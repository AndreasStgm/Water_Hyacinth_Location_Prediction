{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df: pd.DataFrame = pd.read_feather(\"./training_data/processed_data/preprocessed_weather_hartbeespoort.feather\")\n",
    "images_df: pd.DataFrame = pd.read_feather(\"./training_data/processed_data/preprocessed_image_hartbeespoort.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>windspeed</th>\n",
       "      <th>winddir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>18.4</td>\n",
       "      <td>292.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-09</th>\n",
       "      <td>15.4</td>\n",
       "      <td>330.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>21.7</td>\n",
       "      <td>85.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-10</th>\n",
       "      <td>13.6</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-13</th>\n",
       "      <td>16.6</td>\n",
       "      <td>117.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-10</th>\n",
       "      <td>14.8</td>\n",
       "      <td>320.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13</th>\n",
       "      <td>13.9</td>\n",
       "      <td>29.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-15</th>\n",
       "      <td>16.4</td>\n",
       "      <td>183.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-18</th>\n",
       "      <td>11.6</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-20</th>\n",
       "      <td>12.9</td>\n",
       "      <td>288.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            windspeed  winddir\n",
       "datetime                      \n",
       "2021-01-04       18.4    292.2\n",
       "2021-01-09       15.4    330.5\n",
       "2021-01-21       21.7     85.6\n",
       "2021-02-10       13.6     46.0\n",
       "2021-02-13       16.6    117.2\n",
       "...               ...      ...\n",
       "2024-05-10       14.8    320.4\n",
       "2024-05-13       13.9     29.4\n",
       "2024-05-15       16.4    183.5\n",
       "2024-05-18       11.6    218.0\n",
       "2024-05-20       12.9    288.7\n",
       "\n",
       "[319 rows x 2 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center_x_1</th>\n",
       "      <th>center_y_1</th>\n",
       "      <th>x_axis_length_1</th>\n",
       "      <th>y_axis_length_1</th>\n",
       "      <th>angle_1</th>\n",
       "      <th>center_x_2</th>\n",
       "      <th>center_y_2</th>\n",
       "      <th>x_axis_length_2</th>\n",
       "      <th>y_axis_length_2</th>\n",
       "      <th>angle_2</th>\n",
       "      <th>center_x_3</th>\n",
       "      <th>center_y_3</th>\n",
       "      <th>x_axis_length_3</th>\n",
       "      <th>y_axis_length_3</th>\n",
       "      <th>angle_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>704.028564</td>\n",
       "      <td>442.499176</td>\n",
       "      <td>121.826691</td>\n",
       "      <td>451.231567</td>\n",
       "      <td>58.160427</td>\n",
       "      <td>960.999756</td>\n",
       "      <td>336.523529</td>\n",
       "      <td>112.876732</td>\n",
       "      <td>203.835342</td>\n",
       "      <td>117.014908</td>\n",
       "      <td>1092.642456</td>\n",
       "      <td>257.937164</td>\n",
       "      <td>133.023499</td>\n",
       "      <td>147.132126</td>\n",
       "      <td>142.699448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-09</th>\n",
       "      <td>715.279602</td>\n",
       "      <td>351.457184</td>\n",
       "      <td>100.243324</td>\n",
       "      <td>367.353882</td>\n",
       "      <td>66.100555</td>\n",
       "      <td>807.207031</td>\n",
       "      <td>124.622177</td>\n",
       "      <td>54.882431</td>\n",
       "      <td>117.928635</td>\n",
       "      <td>119.937805</td>\n",
       "      <td>184.712097</td>\n",
       "      <td>572.285339</td>\n",
       "      <td>51.416313</td>\n",
       "      <td>93.895416</td>\n",
       "      <td>133.982315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>325.976746</td>\n",
       "      <td>490.977356</td>\n",
       "      <td>136.785980</td>\n",
       "      <td>500.891998</td>\n",
       "      <td>74.853523</td>\n",
       "      <td>813.122131</td>\n",
       "      <td>146.077484</td>\n",
       "      <td>87.973320</td>\n",
       "      <td>149.937958</td>\n",
       "      <td>163.590485</td>\n",
       "      <td>1233.187134</td>\n",
       "      <td>566.028442</td>\n",
       "      <td>8.314092</td>\n",
       "      <td>24.543709</td>\n",
       "      <td>143.964798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-10</th>\n",
       "      <td>167.179871</td>\n",
       "      <td>545.132202</td>\n",
       "      <td>91.021637</td>\n",
       "      <td>191.275513</td>\n",
       "      <td>108.308769</td>\n",
       "      <td>881.044556</td>\n",
       "      <td>144.769745</td>\n",
       "      <td>63.307846</td>\n",
       "      <td>291.755676</td>\n",
       "      <td>111.700424</td>\n",
       "      <td>592.362976</td>\n",
       "      <td>408.737030</td>\n",
       "      <td>60.006161</td>\n",
       "      <td>177.342026</td>\n",
       "      <td>67.738052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-13</th>\n",
       "      <td>280.800171</td>\n",
       "      <td>504.206818</td>\n",
       "      <td>134.417603</td>\n",
       "      <td>405.863342</td>\n",
       "      <td>72.619293</td>\n",
       "      <td>787.453369</td>\n",
       "      <td>126.050583</td>\n",
       "      <td>35.755112</td>\n",
       "      <td>48.203991</td>\n",
       "      <td>129.081055</td>\n",
       "      <td>918.028381</td>\n",
       "      <td>556.878296</td>\n",
       "      <td>14.486405</td>\n",
       "      <td>27.316944</td>\n",
       "      <td>2.405948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-10</th>\n",
       "      <td>777.354004</td>\n",
       "      <td>107.631660</td>\n",
       "      <td>30.748890</td>\n",
       "      <td>90.560562</td>\n",
       "      <td>146.724838</td>\n",
       "      <td>243.170166</td>\n",
       "      <td>542.966003</td>\n",
       "      <td>13.301406</td>\n",
       "      <td>35.620926</td>\n",
       "      <td>173.263412</td>\n",
       "      <td>713.954590</td>\n",
       "      <td>443.647552</td>\n",
       "      <td>9.775264</td>\n",
       "      <td>37.554825</td>\n",
       "      <td>63.395508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13</th>\n",
       "      <td>716.543701</td>\n",
       "      <td>305.779480</td>\n",
       "      <td>22.611246</td>\n",
       "      <td>165.610962</td>\n",
       "      <td>61.839939</td>\n",
       "      <td>120.704819</td>\n",
       "      <td>541.091553</td>\n",
       "      <td>13.267200</td>\n",
       "      <td>20.426884</td>\n",
       "      <td>71.220276</td>\n",
       "      <td>797.884949</td>\n",
       "      <td>141.748245</td>\n",
       "      <td>10.134691</td>\n",
       "      <td>28.270313</td>\n",
       "      <td>174.367538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-15</th>\n",
       "      <td>800.668274</td>\n",
       "      <td>145.144821</td>\n",
       "      <td>26.662622</td>\n",
       "      <td>81.719994</td>\n",
       "      <td>131.096573</td>\n",
       "      <td>756.216187</td>\n",
       "      <td>80.918289</td>\n",
       "      <td>15.954613</td>\n",
       "      <td>37.925011</td>\n",
       "      <td>145.252411</td>\n",
       "      <td>112.768906</td>\n",
       "      <td>556.176453</td>\n",
       "      <td>10.941070</td>\n",
       "      <td>24.187414</td>\n",
       "      <td>82.034576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-18</th>\n",
       "      <td>774.593811</td>\n",
       "      <td>107.590065</td>\n",
       "      <td>32.553211</td>\n",
       "      <td>89.817474</td>\n",
       "      <td>143.160324</td>\n",
       "      <td>233.447922</td>\n",
       "      <td>540.661499</td>\n",
       "      <td>23.895515</td>\n",
       "      <td>50.522202</td>\n",
       "      <td>166.417343</td>\n",
       "      <td>107.577980</td>\n",
       "      <td>557.288330</td>\n",
       "      <td>9.227895</td>\n",
       "      <td>16.054379</td>\n",
       "      <td>118.356796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-20</th>\n",
       "      <td>793.017395</td>\n",
       "      <td>117.654053</td>\n",
       "      <td>46.672836</td>\n",
       "      <td>123.771034</td>\n",
       "      <td>127.777275</td>\n",
       "      <td>235.372681</td>\n",
       "      <td>558.577759</td>\n",
       "      <td>14.813257</td>\n",
       "      <td>34.962509</td>\n",
       "      <td>50.437668</td>\n",
       "      <td>96.132912</td>\n",
       "      <td>525.082397</td>\n",
       "      <td>10.600873</td>\n",
       "      <td>24.264305</td>\n",
       "      <td>133.782135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            center_x_1  center_y_1  x_axis_length_1  y_axis_length_1  \\\n",
       "datetime                                                               \n",
       "2021-01-04  704.028564  442.499176       121.826691       451.231567   \n",
       "2021-01-09  715.279602  351.457184       100.243324       367.353882   \n",
       "2021-01-21  325.976746  490.977356       136.785980       500.891998   \n",
       "2021-02-10  167.179871  545.132202        91.021637       191.275513   \n",
       "2021-02-13  280.800171  504.206818       134.417603       405.863342   \n",
       "...                ...         ...              ...              ...   \n",
       "2024-05-10  777.354004  107.631660        30.748890        90.560562   \n",
       "2024-05-13  716.543701  305.779480        22.611246       165.610962   \n",
       "2024-05-15  800.668274  145.144821        26.662622        81.719994   \n",
       "2024-05-18  774.593811  107.590065        32.553211        89.817474   \n",
       "2024-05-20  793.017395  117.654053        46.672836       123.771034   \n",
       "\n",
       "               angle_1  center_x_2  center_y_2  x_axis_length_2  \\\n",
       "datetime                                                          \n",
       "2021-01-04   58.160427  960.999756  336.523529       112.876732   \n",
       "2021-01-09   66.100555  807.207031  124.622177        54.882431   \n",
       "2021-01-21   74.853523  813.122131  146.077484        87.973320   \n",
       "2021-02-10  108.308769  881.044556  144.769745        63.307846   \n",
       "2021-02-13   72.619293  787.453369  126.050583        35.755112   \n",
       "...                ...         ...         ...              ...   \n",
       "2024-05-10  146.724838  243.170166  542.966003        13.301406   \n",
       "2024-05-13   61.839939  120.704819  541.091553        13.267200   \n",
       "2024-05-15  131.096573  756.216187   80.918289        15.954613   \n",
       "2024-05-18  143.160324  233.447922  540.661499        23.895515   \n",
       "2024-05-20  127.777275  235.372681  558.577759        14.813257   \n",
       "\n",
       "            y_axis_length_2     angle_2   center_x_3  center_y_3  \\\n",
       "datetime                                                           \n",
       "2021-01-04       203.835342  117.014908  1092.642456  257.937164   \n",
       "2021-01-09       117.928635  119.937805   184.712097  572.285339   \n",
       "2021-01-21       149.937958  163.590485  1233.187134  566.028442   \n",
       "2021-02-10       291.755676  111.700424   592.362976  408.737030   \n",
       "2021-02-13        48.203991  129.081055   918.028381  556.878296   \n",
       "...                     ...         ...          ...         ...   \n",
       "2024-05-10        35.620926  173.263412   713.954590  443.647552   \n",
       "2024-05-13        20.426884   71.220276   797.884949  141.748245   \n",
       "2024-05-15        37.925011  145.252411   112.768906  556.176453   \n",
       "2024-05-18        50.522202  166.417343   107.577980  557.288330   \n",
       "2024-05-20        34.962509   50.437668    96.132912  525.082397   \n",
       "\n",
       "            x_axis_length_3  y_axis_length_3     angle_3  \n",
       "datetime                                                  \n",
       "2021-01-04       133.023499       147.132126  142.699448  \n",
       "2021-01-09        51.416313        93.895416  133.982315  \n",
       "2021-01-21         8.314092        24.543709  143.964798  \n",
       "2021-02-10        60.006161       177.342026   67.738052  \n",
       "2021-02-13        14.486405        27.316944    2.405948  \n",
       "...                     ...              ...         ...  \n",
       "2024-05-10         9.775264        37.554825   63.395508  \n",
       "2024-05-13        10.134691        28.270313  174.367538  \n",
       "2024-05-15        10.941070        24.187414   82.034576  \n",
       "2024-05-18         9.227895        16.054379  118.356796  \n",
       "2024-05-20        10.600873        24.264305  133.782135  \n",
       "\n",
       "[319 rows x 15 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preparing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data rows: 287, Test data rows: 32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "result: list[pd.DataFrame] = train_test_split(weather_df, images_df, test_size=0.1, random_state=69, shuffle=False)\n",
    "X_train: pd.DataFrame = result[0]\n",
    "X_valid: pd.DataFrame = result[1]\n",
    "y_train: pd.DataFrame = result[2]\n",
    "y_valid: pd.DataFrame = result[3]\n",
    "\n",
    "print(f\"Training data rows: {len(X_train)}, Test data rows: {len(X_valid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(actual, prediction, data_type) -> None:\n",
    "    print(\"Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\")\n",
    "    print(f\"{data_type} DATA: MSE: {mean_squared_error(actual, prediction)}\")\n",
    "    print(f\"{data_type} DATA: RMSE: {mean_squared_error(actual, prediction, squared=False)}\")\n",
    "    print(f\"{data_type} DATA: MAE: {mean_absolute_error(actual, prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Testing different types of supervised regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "KNOWN DATA: MSE: 0.0\n",
      "KNOWN DATA: RMSE: 0.0\n",
      "KNOWN DATA: MAE: 0.0\n",
      "\n",
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "NEW DATA: MSE: 68636.30911743698\n",
      "NEW DATA: RMSE: 205.61684443192934\n",
      "NEW DATA: MAE: 163.33334224050245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# tree_model = DecisionTreeRegressor(min_samples_split=10, min_samples_leaf=10, min_weight_fraction_leaf=0.3)\n",
    "tree_model = DecisionTreeRegressor()\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "tree_y_pred: np.ndarray = tree_model.predict(X_train)\n",
    "print_metrics(y_train, tree_y_pred, \"KNOWN\")\n",
    "\n",
    "tree_y_pred: np.ndarray = tree_model.predict(X_valid)\n",
    "print_metrics(y_valid, tree_y_pred, \"NEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use GridSearch for attempt at optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32000 candidates, totalling 160000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[209], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m params_tree \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfriedman_mse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoisson\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_impurity_decrease\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m]\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m grid_tree \u001b[38;5;241m=\u001b[39m GridSearchCV(tree_model, param_grid\u001b[38;5;241m=\u001b[39mparams_tree, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mgrid_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m grid_tree\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params_tree = {\n",
    "    \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    \"max_depth\": [None, 2, 4, 10, 20],\n",
    "    \"min_samples_split\": [2, 4, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 5, 10],\n",
    "    \"min_weight_fraction_leaf\": [0.0, 0.1, 0.2, 0.3],\n",
    "    \"max_leaf_nodes\": [None, 6, 8, 10, 20],\n",
    "    \"min_impurity_decrease\": [0.0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "grid_tree = GridSearchCV(tree_model, param_grid=params_tree, n_jobs=-1, verbose=True)\n",
    "\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamter tuning is found empiracally to be a good balance between being to correctly identify known data and handle new data.\n",
    "The problem however is that we have very little data for training and validating.\n",
    "\n",
    "##### Non-default hyperparameters:\n",
    "\n",
    "- min_samples_split (default=2): The minimum number of samples required to split an internal node: If int, then consider min_samples_split as the minimum number. If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.\n",
    "- min_samples_leaf (default=1): The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "\n",
    "- min_weight_fraction_leaf (default=0.0): The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
    "\n",
    "\n",
    "[scikit-learn DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "KNOWN DATA: MSE: 5164.94117209328\n",
      "KNOWN DATA: RMSE: 55.605345003855476\n",
      "KNOWN DATA: MAE: 44.16194339686985\n",
      "\n",
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "NEW DATA: MSE: 41848.94983863062\n",
      "NEW DATA: RMSE: 156.2440174917567\n",
      "NEW DATA: MAE: 129.2070686883852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# forest_model = RandomForestRegressor(min_samples_leaf=10, min_weight_fraction_leaf=0.3)\n",
    "forest_model = RandomForestRegressor()\n",
    "\n",
    "forest_model.fit(X_train, y_train)\n",
    "\n",
    "forest_y_pred: np.ndarray = forest_model.predict(X_train)\n",
    "print_metrics(y_train, forest_y_pred, \"KNOWN\")\n",
    "\n",
    "forest_y_pred: np.ndarray = forest_model.predict(X_valid)\n",
    "print_metrics(y_valid, forest_y_pred, \"NEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use GridSearch for attempt at optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192000 candidates, totalling 960000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m params_forest \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfriedman_mse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoisson\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_impurity_decrease\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m]\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m grid_forest \u001b[38;5;241m=\u001b[39m GridSearchCV(forest_model, param_grid\u001b[38;5;241m=\u001b[39mparams_forest, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mgrid_forest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m grid_forest\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params_forest = {\n",
    "    \"n_estimators\": [10, 25, 50, 100, 200],\n",
    "    \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "    \"max_depth\": [None, 2, 4, 10, 20],\n",
    "    \"min_samples_split\": [2, 4, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 5, 10],\n",
    "    \"min_weight_fraction_leaf\": [0.0, 0.1, 0.2, 0.3],\n",
    "    \"max_leaf_nodes\": [None, 6, 8, 10, 20],\n",
    "    \"min_impurity_decrease\": [0.0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "grid_forest = GridSearchCV(forest_model, param_grid=params_forest, n_jobs=-1, verbose=True)\n",
    "\n",
    "grid_forest.fit(X_train, y_train)\n",
    "\n",
    "grid_forest.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-default hyperparameters:\n",
    "\n",
    "- min_samples_leaf (default=1): The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "- min_weight_fraction_leaf (default=0.0): The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
    "\n",
    "[scikit-learn RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3. Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "KNOWN DATA: MSE: 32412.473880083835\n",
      "KNOWN DATA: RMSE: 140.13840079242888\n",
      "KNOWN DATA: MAE: 114.45904001584911\n",
      "\n",
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "NEW DATA: MSE: 32201.900449802193\n",
      "NEW DATA: RMSE: 139.62326538527105\n",
      "NEW DATA: MAE: 114.78593845659337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# linear_model = LinearRegression(positive=True)\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "linear_y_pred: np.ndarray = linear_model.predict(X_train)\n",
    "print_metrics(y_train, linear_y_pred, \"KNOWN\")\n",
    "\n",
    "linear_y_pred: np.ndarray = linear_model.predict(X_valid)\n",
    "print_metrics(y_valid, linear_y_pred, \"NEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use GridSearch for attempt at optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_linear = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"copy_X\": [True, False],\n",
    "    \"positive\": [False, True]\n",
    "}\n",
    "\n",
    "grid_linear = GridSearchCV(linear_model, param_grid=params_linear, n_jobs=-1, verbose=True)\n",
    "\n",
    "grid_linear.fit(X_train, y_train)\n",
    "\n",
    "grid_linear.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-default hyperparameters:\n",
    "\n",
    "- positive (default=False): When set to True, forces the coefficients to be positive. This option is only supported for dense arrays.\n",
    "\n",
    "[scikit-learn LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "KNOWN DATA: MSE: 32412.473880672176\n",
      "KNOWN DATA: RMSE: 140.13840079471518\n",
      "KNOWN DATA: MAE: 114.45905276457098\n",
      "\n",
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "NEW DATA: MSE: 32201.91389630856\n",
      "NEW DATA: RMSE: 139.62331318445302\n",
      "NEW DATA: MAE: 114.78600015441154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# ridge_model = Ridge(solver=\"lbfgs\", positive=True)\n",
    "ridge_model = Ridge()\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "ridge_y_pred: np.ndarray = ridge_model.predict(X_train)\n",
    "print_metrics(y_train, ridge_y_pred, \"KNOWN\")\n",
    "\n",
    "ridge_y_pred: np.ndarray = ridge_model.predict(X_valid)\n",
    "print_metrics(y_valid, ridge_y_pred, \"NEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use GridSearch for attempt at optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ridge = {\n",
    "    \"alpha\": [1.0, 2.0, 2.5, 5.0, 10.0],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"max_iter\": [None, 1000, 15000, 30000],\n",
    "    \"tol\": [0.0001, 0.001, 0.01, 0.1, 0.00001],\n",
    "    \"solver\": [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\", \"lbfgs\"],\n",
    "    \"positive\": [False, True]\n",
    "}\n",
    "\n",
    "grid_ridge = GridSearchCV(ridge_model, param_grid=params_ridge, n_jobs=-1, verbose=True)\n",
    "\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "\n",
    "grid_ridge.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-default hyperparameters:\n",
    "\n",
    "- solver (default=\"auto\"): Solver to use in the computational routines: â€˜autoâ€™ chooses the solver automatically based on the type of data. â€˜svdâ€™ uses a Singular Value Decomposition of X to compute the Ridge coefficients. It is the most stable solver, in particular more stable for singular matrices than â€˜choleskyâ€™ at the cost of being slower. â€˜choleskyâ€™ uses the standard scipy.linalg.solve function to obtain a closed-form solution. â€˜sparse_cgâ€™ uses the conjugate gradient solver as found in scipy.sparse.linalg.cg. As an iterative algorithm, this solver is more appropriate than â€˜choleskyâ€™ for large-scale data (possibility to set tol and max_iter). â€˜lsqrâ€™ uses the dedicated regularized least-squares routine scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative procedure. â€˜sagâ€™ uses a Stochastic Average Gradient descent, and â€˜sagaâ€™ uses its improved, unbiased version named SAGA. Both methods also use an iterative procedure, and are often faster than other solvers when both n_samples and n_features are large. Note that â€˜sagâ€™ and â€˜sagaâ€™ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing. â€˜lbfgsâ€™ uses L-BFGS-B algorithm implemented in scipy.optimize.minimize. It can be used only when positive is True. All solvers except â€˜svdâ€™ support both dense and sparse data. However, only â€˜lsqrâ€™, â€˜sagâ€™, â€˜sparse_cgâ€™, and â€˜lbfgsâ€™ support sparse input when fit_intercept is True.\n",
    "- positive (default=False): When set to True, forces the coefficients to be positive. Only â€˜lbfgsâ€™ solver is supported in this case.\n",
    "\n",
    "[scikit-learn Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "KNOWN DATA: MSE: 32412.484075229924\n",
      "KNOWN DATA: RMSE: 140.1385092368401\n",
      "KNOWN DATA: MAE: 114.46022118650104\n",
      "\n",
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "NEW DATA: MSE: 32202.681205668472\n",
      "NEW DATA: RMSE: 139.62734251695647\n",
      "NEW DATA: MAE: 114.7960288132233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# lasso_model = Lasso(positive=True)\n",
    "lasso_model = Lasso()\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "lasso_y_pred: np.ndarray = lasso_model.predict(X_train)\n",
    "print_metrics(y_train, lasso_y_pred, \"KNOWN\")\n",
    "\n",
    "lasso_y_pred: np.ndarray = lasso_model.predict(X_valid)\n",
    "print_metrics(y_valid, lasso_y_pred, \"NEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use GridSearch for attempt at optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lasso = {\n",
    "    \"alpha\": [1.0, 2.0, 2.5, 5.0, 10.0],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"max_iter\": [1000, 2000, 5000],\n",
    "    \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"positive\": [False, True],\n",
    "    \"selection\": [\"cyclic\", \"random\"]\n",
    "}\n",
    "\n",
    "grid_lasso = GridSearchCV(lasso_model, param_grid=params_lasso, n_jobs=-1, verbose=True)\n",
    "\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "\n",
    "grid_lasso.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-default hyperparameters:\n",
    "\n",
    "- positive (default=False): When set to True, forces the coefficients to be positive.\n",
    "\n",
    "[scikit-learn Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6. Nearest Neighbour Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "KNOWN DATA: MSE: 30362.396808735983\n",
      "KNOWN DATA: RMSE: 135.82851850619156\n",
      "KNOWN DATA: MAE: 109.82000238432865\n",
      "\n",
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "NEW DATA: MSE: 33495.226513995294\n",
      "NEW DATA: RMSE: 141.74131716314858\n",
      "NEW DATA: MAE: 116.26705300511918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# neighbour_model = KNeighborsRegressor(n_neighbors=25)\n",
    "neighbour_model = KNeighborsRegressor()\n",
    "\n",
    "neighbour_model.fit(X_train, y_train)\n",
    "\n",
    "neighbour_y_pred: np.ndarray = neighbour_model.predict(X_train)\n",
    "print_metrics(y_train, neighbour_y_pred, \"KNOWN\")\n",
    "\n",
    "neighbour_y_pred: np.ndarray = neighbour_model.predict(X_valid)\n",
    "print_metrics(y_valid, neighbour_y_pred, \"NEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use GridSearch for attempt at optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_neighbour = {\n",
    "    \"n_neighbours\": [5, 10, 15, 20, 25, 50, 100],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"leaf_size\": [30, 10, 5, 50, 100],\n",
    "    \"p\": [2.0, 3.0, 5.0, 10.0, 1.0]\n",
    "}\n",
    "\n",
    "grid_neighbour = GridSearchCV(neighbour_model, param_grid=params_neighbour, n_jobs=-1, verbose=True)\n",
    "\n",
    "grid_neighbour.fit(X_train, y_train)\n",
    "\n",
    "grid_neighbour.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-default hyperparameters:\n",
    "\n",
    "- n_neighbours (default=5): Number of neighbors to use by default for kneighbors queries.\n",
    "\n",
    "[scikit-learn KNeighboursRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.7. Multi-Layer Perceptron (MLP) Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "KNOWN DATA: MSE: 35837.88473947572\n",
      "KNOWN DATA: RMSE: 148.61863051041124\n",
      "KNOWN DATA: MAE: 121.48386304759583\n",
      "\n",
      "Mean Squared Error, Root Mean Squared Error, Mean Absolute Error (perfect = 0.0)\n",
      "NEW DATA: MSE: 34417.703978671394\n",
      "NEW DATA: RMSE: 148.3825567469038\n",
      "NEW DATA: MAE: 121.94880738534113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# mlp_model = MLPRegressor(solver=\"lbfgs\")\n",
    "mlp_model = MLPRegressor()\n",
    "\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "mlp_y_pred: np.ndarray = mlp_model.predict(X_train)\n",
    "print_metrics(y_train, mlp_y_pred, \"KNOWN\")\n",
    "\n",
    "mlp_y_pred: np.ndarray = mlp_model.predict(X_valid)\n",
    "print_metrics(y_valid, mlp_y_pred, \"NEW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use GridSearch for attempt at optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_mlp = {\n",
    "    \"hidden_layer_sizes\": [[100, 0], [500, 0], [1000, 0]],\n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    \"tol\": [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "grid_mlp = GridSearchCV(mlp_model, param_grid=params_mlp, n_jobs=-1, verbose=True)\n",
    "\n",
    "grid_mlp.fit(X_train, y_train)\n",
    "\n",
    "grid_mlp.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-default hyperparameters:\n",
    "\n",
    "- solver (default=\"adam\"): The solver for weight optimization. â€˜lbfgsâ€™ is an optimizer in the family of quasi-Newton methods. â€˜sgdâ€™ refers to stochastic gradient descent. â€˜adamâ€™ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba. Note: The default solver â€˜adamâ€™ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, â€˜lbfgsâ€™ can converge faster and perform better.\n",
    "\n",
    "[scikit-learn MLP Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Testing timeseries model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 Preparing data for timeseries analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the index to a datetimeindex\n",
    "# weather_df.index = pd.to_datetime(weather_df.index)\n",
    "# images_df.index = pd.to_datetime(images_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from darts import TimeSeries\n",
    "\n",
    "# weather_ts: TimeSeries = TimeSeries.from_dataframe(weather_df, fill_missing_dates=True)\n",
    "# image_ts: TimeSeries = TimeSeries.from_dataframe(images_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
